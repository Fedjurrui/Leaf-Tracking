{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os,natsort\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "from modelTraining.modelDefinition import get_instance_segmentation_model\n",
    "from DatasetUtils.FimgHandling import normalizeImg,cutTrayInIndividualImages, prepareForModel\n",
    "from DatasetUtils.ConvenientFunctions import get_average_and_store, create_time_series\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "sns.reset_defaults()\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MaskRCNN(\n  (transform): GeneralizedRCNNTransform(\n      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n  )\n  (backbone): BackboneWithFPN(\n    (body): IntermediateLayerGetter(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): FrozenBatchNorm2d(256, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(512, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(1024, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(2048, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (fpn): FeaturePyramidNetwork(\n      (inner_blocks): ModuleList(\n        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (layer_blocks): ModuleList(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (extra_blocks): LastLevelMaxPool()\n    )\n  )\n  (rpn): RegionProposalNetwork(\n    (anchor_generator): AnchorGenerator()\n    (head): RPNHead(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (roi_heads): RoIHeads(\n    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n    (box_head): TwoMLPHead(\n      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNPredictor(\n      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n    )\n    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n    (mask_head): MaskRCNNHeads(\n      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (relu1): ReLU(inplace=True)\n      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (relu2): ReLU(inplace=True)\n      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (relu3): ReLU(inplace=True)\n      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (relu4): ReLU(inplace=True)\n    )\n    (mask_predictor): MaskRCNNPredictor(\n      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n      (relu): ReLU(inplace=True)\n      (mask_fcn_logits): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model =get_instance_segmentation_model(2)\n",
    "stateDict = torch.load(\"Models/Leaf_Segmentation_MaskedRCNN_7_7_2022_8h.h5\",map_location=device)\n",
    "model.load_state_dict(stateDict)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Images ordering\n",
    "As the dataset requires a previous work on ordering due to export labeling issues, here we provide the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/57 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0db60af4f07b43d6a66f963d45efe487"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/57 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "734d46ce11254869a6dd9a2e56f5d727"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder_path1 = \"Datasets/Tracking_validation_dataset/ParametersImages_8_DAS_17\"\n",
    "folder_path2 = \"Datasets/Tracking_validation_dataset/ParametersImages_18_DAS_26\"\n",
    "folder_path3 = \"Datasets/Tracking_validation_dataset/ParametersImages\"\n",
    "tray_ID = \"002\"\n",
    "files1 = os.listdir(folder_path1)\n",
    "files1 = [e for e in files1 if e.endswith(\"Fmp.fimg\")]\n",
    "files1 = natsort.natsorted([folder_path1+\"/\"+e for e in files1 if tray_ID in e])\n",
    "files2 = os.listdir(folder_path2)\n",
    "files2 = [e for e in files2 if e.endswith(\"Fmp.fimg\")]\n",
    "files2 = natsort.natsorted([folder_path2+\"/\"+e for e in files2 if tray_ID in e])\n",
    "files12 =files1 + files2\n",
    "files3 = os.listdir(folder_path3)\n",
    "files3 = [e for e in files3 if (e.endswith(\"Fm.fimg\") and not (e.endswith(\"Fv_Fm.fimg\")))]\n",
    "files3 = natsort.natsorted([folder_path3+\"/\"+e for e in files3 if tray_ID in e])\n",
    "files = []\n",
    "for i in range(len(files3)):\n",
    "    files += [files3[0]]\n",
    "    files +=files12[0:2]\n",
    "    files3.pop(0)\n",
    "    files12.pop(0)\n",
    "    files12.pop(0)\n",
    "tray = []\n",
    "normalized_tray = []\n",
    "for i in tnrange(len(files)):\n",
    "    fimg_path = files[i]\n",
    "    this_tray = cutTrayInIndividualImages(fimg_path,normalized=False)\n",
    "    images = []\n",
    "    for e in this_tray:\n",
    "        img = e.copy()\n",
    "        img[img < 0]= 0\n",
    "        images.append(img)\n",
    "    tray.append(images)\n",
    "    this_normalized_tray = [normalizeImg(e,torch_format=True) for e in images]\n",
    "    this_normalized_tray = prepareForModel(this_normalized_tray)\n",
    "    normalized_tray.append(this_normalized_tray)\n",
    "folder_path1 = \"Datasets/Tracking_validation_dataset/ParametersImages_8_DAS_17\"\n",
    "folder_path2 = \"Datasets/Tracking_validation_dataset/ParametersImages_18_DAS_26\"\n",
    "folder_path3 = \"Datasets/Tracking_validation_dataset/ParametersImages\"\n",
    "files1 = os.listdir(folder_path1)\n",
    "files1 = [e for e in files1 if e.endswith(\"Fp.fimg\")]\n",
    "files1 = natsort.natsorted([folder_path1+\"/\"+e for e in files1 if tray_ID in e])\n",
    "files2 = os.listdir(folder_path2)\n",
    "files2 = [e for e in files2 if e.endswith(\"Fp.fimg\")]\n",
    "files2 = natsort.natsorted([folder_path2+\"/\"+e for e in files2 if tray_ID in e])\n",
    "files12 =files1 + files2\n",
    "files3 = os.listdir(folder_path3)\n",
    "files3 = [e for e in files3 if (e.endswith(\"Fo.fimg\") and not (e.endswith(\"Fv_Fm.fimg\")))]\n",
    "files3 = natsort.natsorted([folder_path3+\"/\"+e for e in files3 if tray_ID in e])\n",
    "files = []\n",
    "for i in range(len(files3)):\n",
    "    files += [files3[0]]\n",
    "    files +=files12[0:2]\n",
    "    files3.pop(0)\n",
    "    files12.pop(0)\n",
    "    files12.pop(0)\n",
    "\n",
    "tray_fo = []\n",
    "for i in tnrange(len(files)):\n",
    "    fimg_path = files[i]\n",
    "    this_tray_fo = cutTrayInIndividualImages(fimg_path, normalized=False)\n",
    "    images = []\n",
    "    for e in this_tray_fo:\n",
    "        img = e.copy()\n",
    "        img[img < 0] = 0\n",
    "        images.append(img)\n",
    "    tray_fo.append(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model usage\n",
    "Eventhough this cell is does not require GPU to run, it is highly encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/57 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6775bae4e1a24b79845974e638287663"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if device.type == \"cuda\":\n",
    "    results = []\n",
    "    for i in tqdm(normalized_tray):\n",
    "        i = i.cuda()\n",
    "        this_result = model(i)\n",
    "        for idx,result in enumerate(this_result):\n",
    "            for k,v in result.items():\n",
    "                result[k] = v.detach().cpu()\n",
    "            this_result[idx] = result\n",
    "        results.append(this_result)\n",
    "        del result\n",
    "        del v\n",
    "        del this_result\n",
    "        del i\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    results = []\n",
    "    for i in tqdm(normalized_tray):\n",
    "        this_result=model(i)\n",
    "        for idx,result in enumerate(this_result):\n",
    "            for k,v in result.items():\n",
    "                result[k] = v.detach()\n",
    "            this_result[idx] = result\n",
    "        results.append(this_result)\n",
    "        del this_result\n",
    "        del i\n",
    "        del v\n",
    "        del result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Running the association process and information store\n",
    "\n",
    "In the following cell we perform the tracking as described in the manuscript. We also perform the PSII, Fmp, and Fp analysis and estimation, all wrapped in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd9dbd286c8c43e98831b2da666543e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trays_order =[\"A1\",\"B1\",\"C1\",\"A2\",\"B2\",\"C2\",\"A3\",\"B3\",\"C3\"]\n",
    "tray_number = \"002\"\n",
    "tray_name = \"example_tray\"\n",
    "for i in tnrange(9):\n",
    "\n",
    "    name = trays_order[i]\n",
    "    time_series, series,images = create_time_series(tray,results,index=i)\n",
    "\n",
    "\n",
    "    get_average_and_store(path=\"{}_{}\".format(tray_name,tray_number),\n",
    "                          time_series=time_series,\n",
    "                          series=series,\n",
    "                          images=images,\n",
    "                          name=name,\n",
    "                          line_plot=True,\n",
    "                          gif=True,\n",
    "                          save_masks=True,\n",
    "                          save_fcam_values=True,\n",
    "                          type=\"Fmp\")\n",
    "    images_fo = []\n",
    "    for e in tray_fo:\n",
    "        img = e[i].copy()\n",
    "        img[img < 0]= 0\n",
    "        images_fo.append(img)\n",
    "    get_average_and_store(path=\"{}_{}\".format(tray_name,tray_number),\n",
    "                          time_series=time_series,\n",
    "                          series=series,\n",
    "                          images=images_fo,\n",
    "                          name=name,\n",
    "                          line_plot=True,\n",
    "                          gif=False,\n",
    "                          save_masks=False,\n",
    "                          save_fcam_values=True,\n",
    "                          type=\"Fo\")\n",
    "    df1 = pd.read_csv(\"{}_{}/{}/{}_Fmp_Average_Flcam_values_per_leaf.tsv\".format(tray_name,tray_number,name,name),\n",
    "                      sep=\"\\t\",\n",
    "                      index_col=0)\n",
    "    df2 = pd.read_csv(\"{}_{}/{}/{}_Fo_Average_Flcam_values_per_leaf.tsv\".format(tray_name,tray_number,name,name),\n",
    "                      sep=\"\\t\",\n",
    "                      index_col=0)\n",
    "    val = (df1.values - df2.values)\n",
    "    val[val < 0] = 0\n",
    "    val = val/df1.values\n",
    "    total_average = pd.DataFrame(val)\n",
    "    total_average.to_csv(\"{}_{}/{}/{}_phiPSII_Average_Flcam_values_per_leaf.tsv\".format(tray_name,tray_number,name,name),\n",
    "                             sep=\"\\t\")\n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.lineplot(data=total_average)\n",
    "    plt.xticks(total_average.index.tolist())\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"{}_{}/{}\".format(tray_name,tray_number,name,name)\n",
    "                             ,\"{}_phiPSII_graph.png\".format(name)),dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torchGPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "118487b1b61bd11bfc0fa122cb4895870a0a05b9d302d1e57edad66962da4c3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
